{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Untuk melihat bagaimana efektifnya transfer learning, kita akan mencoba menggunakan transfer learning pada dataset cheesman yang kita kerjakan pada project sebelumnya."
      ],
      "metadata": {
        "id": "smFjhJ3bGpjz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_FoI6-gGHUA",
        "outputId": "6b8ce640-ca7d-4238-8f4b-01955cace722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-16 01:49:36--  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip [following]\n",
            "--2022-11-16 01:49:36--  https://raw.githubusercontent.com/dicodingacademy/assets/main/ml_pengembangan_academy/Chessman-image-dataset.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 60684125 (58M) [application/zip]\n",
            "Saving to: ‘/tmp/Chessman-image-dataset.zip’\n",
            "\n",
            "/tmp/Chessman-image 100%[===================>]  57.87M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-16 01:49:39 (410 MB/s) - ‘/tmp/Chessman-image-dataset.zip’ saved [60684125/60684125]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "  https://github.com/dicodingacademy/assets/raw/main/ml_pengembangan_academy/Chessman-image-dataset.zip \\\n",
        "  -O /tmp/Chessman-image-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kemudian, kita buat direktori untuk dataset kita untuk digunakan pada ImageDataGenerator. "
      ],
      "metadata": {
        "id": "3e9laOiVG7fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#unzip terlebih dahulu\n",
        "import os\n",
        "import zipfile\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "local_zip = '/tmp/Chessman-image-dataset.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "#tentukan direktori\n",
        "train_dir = os.path.join('/tmp/Chessman-image-dataset/Chess')\n",
        "\n",
        "#imagedatagenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.1) # set validation split"
      ],
      "metadata": {
        "id": "TKqxK3w0G1Ym"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bagi dataset menjadi data training dan data validasi."
      ],
      "metadata": {
        "id": "V4Y-eBVgHK5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=8,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    train_dir, # same directory as training data\n",
        "    target_size=(150, 150),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWsiMnzbHKGR",
        "outputId": "54e1abcd-db70-4f5e-dcd8-2b292062fd5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 499 images belonging to 6 classes.\n",
            "Found 52 images belonging to 6 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nah, disini kita mulai mengimplementasikan transfer learning. Untuk model yang kita pilih sebagai model dasar transfer learning adalah ResNet152V2. Model ResNet152V2 memiliki sebanyak 152 layer dan tersedia di library keras."
      ],
      "metadata": {
        "id": "a4AyWYIJHnIk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk mengimplementasikan transfer learning sangatlah mudah seperti kode di bawah. Kita hanya perlu menambahkan 2 buah baris kode berbeda. Layer pertama pada model kita adalah model yang kita pakai untuk transfer learning. Kita cukup memanggil kelas ResNet152V2 dan mengisi parameter sebagai berikut:\n",
        "\n",
        "1. Weight : ini adalah bobot atau parameter seperti yang telah dibahas pada kelas machine learning pemula. Untuk parameter weight kita mengisi nilai ‘imagenet’. Artinya kita ingin menggunakan model ResNet152V2 yang telah dilatih pada dataset imagenet. Imagenet adalah sebuah database raksasa yang berisi lebih dari 14 juta gambar.\n",
        "\n",
        "2. Include_top : parameter ini bernilai boolean. Maksud dari parameter ini apabila kita ingin tetap memakai layer terakhir/layer prediksi dari model resnet. Kita isi false karena kita memakai model resnet untuk memprediksi dataset chessman bukan imagenet.\n",
        "\n",
        "3. Input_tensor : sesuai namanya parameter ini menspesifikasikan ukuran dari input."
      ],
      "metadata": {
        "id": "YekfAcqMHpiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications import ResNet152V2\n",
        "model = tf.keras.models.Sequential([\n",
        "    ResNet152V2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(150, 150, 3))),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(), \n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(6, activation='softmax')  \n",
        "])\n",
        "model.layers[0].trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzhd0gU6HyQs",
        "outputId": "af49c3cc-2565-485c-9563-f3478dd8d8c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234545216/234545216 [==============================] - 8s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lanjutkan dengan menentukan optimizer, loss, serta metrik yang ingin digunakan pada model."
      ],
      "metadata": {
        "id": "NQDk00dgH_AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "incyeUNkH0Ky"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Terakhir kita dapat melakukan pelatihan model. "
      ],
      "metadata": {
        "id": "UdfsuMcQICX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,\n",
        "                              validation_data=validation_generator,\n",
        "                              epochs=50,\n",
        "                              verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_6abvHgIEDV",
        "outputId": "7c94048d-a0fe-42a5-e270-eaa88a4e3df3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "63/63 - 29s - loss: 8.8984 - accuracy: 0.4529 - val_loss: 3.5441 - val_accuracy: 0.5769 - 29s/epoch - 467ms/step\n",
            "Epoch 2/50\n",
            "63/63 - 10s - loss: 2.0014 - accuracy: 0.6754 - val_loss: 2.0098 - val_accuracy: 0.5962 - 10s/epoch - 166ms/step\n",
            "Epoch 3/50\n",
            "63/63 - 10s - loss: 1.5972 - accuracy: 0.7275 - val_loss: 1.3753 - val_accuracy: 0.7692 - 10s/epoch - 161ms/step\n",
            "Epoch 4/50\n",
            "63/63 - 10s - loss: 1.0407 - accuracy: 0.7715 - val_loss: 1.4824 - val_accuracy: 0.5962 - 10s/epoch - 159ms/step\n",
            "Epoch 5/50\n",
            "63/63 - 10s - loss: 0.9130 - accuracy: 0.7996 - val_loss: 1.9927 - val_accuracy: 0.6346 - 10s/epoch - 159ms/step\n",
            "Epoch 6/50\n",
            "63/63 - 10s - loss: 0.9909 - accuracy: 0.7916 - val_loss: 1.4061 - val_accuracy: 0.6346 - 10s/epoch - 161ms/step\n",
            "Epoch 7/50\n",
            "63/63 - 11s - loss: 0.8133 - accuracy: 0.8136 - val_loss: 1.4058 - val_accuracy: 0.7115 - 11s/epoch - 176ms/step\n",
            "Epoch 8/50\n",
            "63/63 - 10s - loss: 0.7522 - accuracy: 0.8317 - val_loss: 1.2607 - val_accuracy: 0.6923 - 10s/epoch - 161ms/step\n",
            "Epoch 9/50\n",
            "63/63 - 10s - loss: 0.4569 - accuracy: 0.8697 - val_loss: 0.9580 - val_accuracy: 0.7692 - 10s/epoch - 162ms/step\n",
            "Epoch 10/50\n",
            "63/63 - 11s - loss: 0.4083 - accuracy: 0.9058 - val_loss: 1.4245 - val_accuracy: 0.6731 - 11s/epoch - 177ms/step\n",
            "Epoch 11/50\n",
            "63/63 - 10s - loss: 0.8601 - accuracy: 0.8477 - val_loss: 1.1270 - val_accuracy: 0.7308 - 10s/epoch - 160ms/step\n",
            "Epoch 12/50\n",
            "63/63 - 10s - loss: 0.6223 - accuracy: 0.8577 - val_loss: 1.2286 - val_accuracy: 0.6923 - 10s/epoch - 161ms/step\n",
            "Epoch 13/50\n",
            "63/63 - 10s - loss: 0.4952 - accuracy: 0.8717 - val_loss: 2.3073 - val_accuracy: 0.7115 - 10s/epoch - 160ms/step\n",
            "Epoch 14/50\n",
            "63/63 - 12s - loss: 0.4117 - accuracy: 0.9018 - val_loss: 1.8059 - val_accuracy: 0.6731 - 12s/epoch - 189ms/step\n",
            "Epoch 15/50\n",
            "63/63 - 10s - loss: 0.5300 - accuracy: 0.8978 - val_loss: 1.0109 - val_accuracy: 0.7500 - 10s/epoch - 160ms/step\n",
            "Epoch 16/50\n",
            "63/63 - 10s - loss: 0.2642 - accuracy: 0.9399 - val_loss: 1.2490 - val_accuracy: 0.7115 - 10s/epoch - 160ms/step\n",
            "Epoch 17/50\n",
            "63/63 - 10s - loss: 0.4564 - accuracy: 0.8998 - val_loss: 1.0525 - val_accuracy: 0.7692 - 10s/epoch - 163ms/step\n",
            "Epoch 18/50\n",
            "63/63 - 10s - loss: 0.6305 - accuracy: 0.8818 - val_loss: 1.8609 - val_accuracy: 0.7500 - 10s/epoch - 163ms/step\n",
            "Epoch 19/50\n",
            "63/63 - 10s - loss: 0.6808 - accuracy: 0.8938 - val_loss: 2.3017 - val_accuracy: 0.7308 - 10s/epoch - 160ms/step\n",
            "Epoch 20/50\n",
            "63/63 - 11s - loss: 0.2844 - accuracy: 0.9238 - val_loss: 1.0236 - val_accuracy: 0.8077 - 11s/epoch - 175ms/step\n",
            "Epoch 21/50\n",
            "63/63 - 10s - loss: 0.3886 - accuracy: 0.9098 - val_loss: 1.2892 - val_accuracy: 0.7692 - 10s/epoch - 161ms/step\n",
            "Epoch 22/50\n",
            "63/63 - 10s - loss: 0.2598 - accuracy: 0.9198 - val_loss: 1.2822 - val_accuracy: 0.6346 - 10s/epoch - 159ms/step\n",
            "Epoch 23/50\n",
            "63/63 - 10s - loss: 0.3063 - accuracy: 0.9238 - val_loss: 1.3541 - val_accuracy: 0.7308 - 10s/epoch - 163ms/step\n",
            "Epoch 24/50\n",
            "63/63 - 10s - loss: 0.2647 - accuracy: 0.9379 - val_loss: 1.6211 - val_accuracy: 0.6346 - 10s/epoch - 163ms/step\n",
            "Epoch 25/50\n",
            "63/63 - 10s - loss: 0.2270 - accuracy: 0.9479 - val_loss: 1.0288 - val_accuracy: 0.7885 - 10s/epoch - 161ms/step\n",
            "Epoch 26/50\n",
            "63/63 - 10s - loss: 0.1447 - accuracy: 0.9599 - val_loss: 1.4826 - val_accuracy: 0.7500 - 10s/epoch - 161ms/step\n",
            "Epoch 27/50\n",
            "63/63 - 11s - loss: 0.1657 - accuracy: 0.9519 - val_loss: 1.0475 - val_accuracy: 0.7692 - 11s/epoch - 177ms/step\n",
            "Epoch 28/50\n",
            "63/63 - 10s - loss: 0.1308 - accuracy: 0.9659 - val_loss: 1.2510 - val_accuracy: 0.7692 - 10s/epoch - 161ms/step\n",
            "Epoch 29/50\n",
            "63/63 - 10s - loss: 0.0951 - accuracy: 0.9760 - val_loss: 0.9770 - val_accuracy: 0.8462 - 10s/epoch - 163ms/step\n",
            "Epoch 30/50\n",
            "63/63 - 10s - loss: 0.0581 - accuracy: 0.9820 - val_loss: 1.1669 - val_accuracy: 0.8269 - 10s/epoch - 160ms/step\n",
            "Epoch 31/50\n",
            "63/63 - 10s - loss: 0.1888 - accuracy: 0.9659 - val_loss: 1.4817 - val_accuracy: 0.7500 - 10s/epoch - 161ms/step\n",
            "Epoch 32/50\n",
            "63/63 - 10s - loss: 0.1848 - accuracy: 0.9559 - val_loss: 1.9845 - val_accuracy: 0.6923 - 10s/epoch - 160ms/step\n",
            "Epoch 33/50\n",
            "63/63 - 10s - loss: 0.1637 - accuracy: 0.9659 - val_loss: 1.9904 - val_accuracy: 0.6346 - 10s/epoch - 162ms/step\n",
            "Epoch 34/50\n",
            "63/63 - 11s - loss: 0.2707 - accuracy: 0.9379 - val_loss: 2.1426 - val_accuracy: 0.7115 - 11s/epoch - 176ms/step\n",
            "Epoch 35/50\n",
            "63/63 - 10s - loss: 0.2458 - accuracy: 0.9439 - val_loss: 1.2635 - val_accuracy: 0.8462 - 10s/epoch - 162ms/step\n",
            "Epoch 36/50\n",
            "63/63 - 10s - loss: 0.2793 - accuracy: 0.9439 - val_loss: 1.7330 - val_accuracy: 0.7692 - 10s/epoch - 161ms/step\n",
            "Epoch 37/50\n",
            "63/63 - 10s - loss: 0.4698 - accuracy: 0.9299 - val_loss: 2.7529 - val_accuracy: 0.6731 - 10s/epoch - 161ms/step\n",
            "Epoch 38/50\n",
            "63/63 - 11s - loss: 0.2668 - accuracy: 0.9279 - val_loss: 0.8489 - val_accuracy: 0.7692 - 11s/epoch - 177ms/step\n",
            "Epoch 39/50\n",
            "63/63 - 10s - loss: 0.3103 - accuracy: 0.9459 - val_loss: 1.2077 - val_accuracy: 0.7692 - 10s/epoch - 162ms/step\n",
            "Epoch 40/50\n",
            "63/63 - 11s - loss: 0.2352 - accuracy: 0.9479 - val_loss: 1.9214 - val_accuracy: 0.7308 - 11s/epoch - 176ms/step\n",
            "Epoch 41/50\n",
            "63/63 - 10s - loss: 0.1767 - accuracy: 0.9539 - val_loss: 1.5509 - val_accuracy: 0.7885 - 10s/epoch - 162ms/step\n",
            "Epoch 42/50\n",
            "63/63 - 10s - loss: 0.2636 - accuracy: 0.9539 - val_loss: 1.5621 - val_accuracy: 0.7500 - 10s/epoch - 160ms/step\n",
            "Epoch 43/50\n",
            "63/63 - 10s - loss: 0.2165 - accuracy: 0.9499 - val_loss: 1.6753 - val_accuracy: 0.7885 - 10s/epoch - 161ms/step\n",
            "Epoch 44/50\n",
            "63/63 - 10s - loss: 0.1481 - accuracy: 0.9599 - val_loss: 1.1084 - val_accuracy: 0.8462 - 10s/epoch - 161ms/step\n",
            "Epoch 45/50\n",
            "63/63 - 10s - loss: 0.2437 - accuracy: 0.9579 - val_loss: 2.4938 - val_accuracy: 0.6731 - 10s/epoch - 161ms/step\n",
            "Epoch 46/50\n",
            "63/63 - 11s - loss: 0.2446 - accuracy: 0.9439 - val_loss: 1.3201 - val_accuracy: 0.7692 - 11s/epoch - 176ms/step\n",
            "Epoch 47/50\n",
            "63/63 - 10s - loss: 0.1791 - accuracy: 0.9519 - val_loss: 1.3672 - val_accuracy: 0.7308 - 10s/epoch - 162ms/step\n",
            "Epoch 48/50\n",
            "63/63 - 10s - loss: 0.1772 - accuracy: 0.9739 - val_loss: 0.9348 - val_accuracy: 0.7500 - 10s/epoch - 161ms/step\n",
            "Epoch 49/50\n",
            "63/63 - 10s - loss: 0.0755 - accuracy: 0.9760 - val_loss: 1.0332 - val_accuracy: 0.7885 - 10s/epoch - 161ms/step\n",
            "Epoch 50/50\n",
            "63/63 - 10s - loss: 0.1325 - accuracy: 0.9719 - val_loss: 1.1974 - val_accuracy: 0.7692 - 10s/epoch - 160ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tingkat akurasi menunjukkan hasil yang jauh lebih baik dibandingkan ketika melatih model sendiri dari awal. Akurasi dari model meningkat 40% menjadi 70 pada epoch terakhir. Hasil ini sangat luar biasa mengingat setiap kelas pada sampel kita sangat sedikit yaitu kurang dari 100 buah sampel."
      ],
      "metadata": {
        "id": "gnYiEBtAIX3D"
      }
    }
  ]
}
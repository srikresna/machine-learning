{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Penggunaan Batch Loading </h1>\n",
        "\n",
        "Batch loading adalah proses pelatihan dimana jst melakukan pembaruan parameternya(weight) setelah membaca sejumlah sampel data tertentu. Misal dataset kita berisi 800 buah gambar pizza. Tanpa batch size, proses pembaruan parameter terjadi untuk selutuh sampel pada dataset. Sehingga ketika tanpa menggunakan batch size, pada 1 epoch terdapat 800 kali pembaruan weight. Ketika 1 ukuran batch adalah 32 buah gambar pizza, maka terdapat 25 batch pada dataset."
      ],
      "metadata": {
        "id": "akjiktQZuXfh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qqXV8JG6uPEU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#kita memakai dataset mnist\n",
        "mnist = tf.keras.datasets.mnist\n",
        "#pisahkan\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "#buat model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (28, 28)),\n",
        "                                    tf.keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)])\n",
        "#compile\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disini kita mulai menggunakan batch loading. Untuk menggunakan batch loading kita hanya tinggal menambahkan parameter ‘batch_size’ pada fungsi fit(). Tahukah Anda bahwa fungsi fit() secara default menggunakan batch loading dengan batch size sebesar 32. Lantas  ketika kita tidak mendefinisikan parameter batch_size, maka ukuran batch akan diisi sebesar 32 secara default. Perhatikan bahwa pada setiap epoch memakan waktu selama sekitar 3 atau 4 detik."
      ],
      "metadata": {
        "id": "Lj98nBr9wbpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, batch_size = 32, epochs = 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMLgGvh6wpMw",
        "outputId": "73254eb0-2657-4448-8db9-54c6a2d7080d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2601 - accuracy: 0.9245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1172 - accuracy: 0.9652\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0810 - accuracy: 0.9762\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0602 - accuracy: 0.9815\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0471 - accuracy: 0.9859\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3e0d3af90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita akan menggunakan batch_size yang lebih besar yaitu 128. Dapat kita lihat bahwa semakin besar batch size, waktu eksekusi tiap epoch akan semakin cepat."
      ],
      "metadata": {
        "id": "YLrvOO2iwwfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(training_images, training_labels, batch_size=128, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojGjqfDSwuu1",
        "outputId": "fe2b4b56-38f3-4c01-9487-84ad376a4c72"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0254 - accuracy: 0.9934\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9952\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0188 - accuracy: 0.9958\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0167 - accuracy: 0.9966\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0150 - accuracy: 0.9971\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3dd5bc4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada latihan ini kita telah memahami bahwa dengan menggunakan batch loading, kita dapat mempercepat pelatihan model kita. Untuk pemilihan batch size sendiri tidak ada aturan bakunya namun yang umum dipakai adalah 32,64, dan 128. Anda umumnya harus bereksperimen sendiri guna menemukan batch size yang cocok dengan masalah Anda. "
      ],
      "metadata": {
        "id": "re5t07dAxnHp"
      }
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb3a686",
   "metadata": {},
   "source": [
    "# OCR WITH TESSERACT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfb12805",
   "metadata": {},
   "source": [
    "Tesseract overview: https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/33418.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4121be",
   "metadata": {},
   "source": [
    "## Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc7ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c28b8b",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d0109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import sys, re\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d574b9",
   "metadata": {},
   "source": [
    "## 1. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29d457f",
   "metadata": {},
   "source": [
    "### 1.1 Convert data to bitmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637044d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_path = 'Data/A.jpeg'\n",
    "image = cv2.imread(image_path)\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5cd069",
   "metadata": {},
   "source": [
    "### 1.2 Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef6c4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73d3f8",
   "metadata": {},
   "source": [
    "### 1.3 Tresholding\n",
    "\n",
    "convert to black-and-white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b367c21d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5606b7c5",
   "metadata": {},
   "source": [
    "### Check vector from black-and-white image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a54b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 8\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "  \n",
    "# resize image\n",
    "resized = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "gray_r = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "thresh_r = cv2.threshold(gray_r, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "print(thresh_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd01d12d",
   "metadata": {},
   "source": [
    "#### Create Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce603ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(gray, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    plt.imshow(cv2.cvtColor(thresh, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    return thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = preprocessing('Data/2_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6236ac22",
   "metadata": {},
   "source": [
    "## 2. Pytesseract    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f0e1d",
   "metadata": {},
   "source": [
    "### Cutsom Configuration\n",
    "\n",
    "Page segmentation modes:\n",
    "\n",
    "0. Orientation and script detection (OSD) only.\n",
    "1. Automatic page segmentation with OSD.\n",
    "2. Automatic page segmentation, but no OSD, or OCR. (not implemented)\n",
    "3. Fully automatic page segmentation, but no OSD. (Default)\n",
    "4. Assume a single column of text of variable sizes.\n",
    "5. Assume a single uniform block of vertically aligned text.\n",
    "6. Assume a single uniform block of text.\n",
    "7. Treat the image as a single text line.\n",
    "8. Treat the image as a single word.\n",
    "9. Treat the image as a single word in a circle.\n",
    "10. Treat the image as a single character.\n",
    "11. Sparse text. Find as much text as possible in no particular order.\n",
    "12. Sparse text with OSD.\n",
    "13. Raw line. Treat the image as a single text line, bypassing hacks that are Tesseract-specific.\n",
    "\n",
    "\n",
    "OCR Engine modes:\n",
    "\n",
    "0. Legacy engine only.\n",
    "1. Neural nets LSTM engine only.\n",
    "2. Legacy + LSTM engines.\n",
    "3. Default, based on what is available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8f6a6e",
   "metadata": {},
   "source": [
    "## 2.1 Pytesseract Image to String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb0ce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_string(file_path, oem=3, psm=3):\n",
    "    bnw = preprocessing(file_path)\n",
    "    custom_config = r\"--oem \"+str(oem)+\" --psm \"+str(psm)\n",
    "    text = pytesseract.image_to_string(bnw, config=custom_config, lang=\"ind\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7927002b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = image_to_string('Data/2_2.png')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3c37c8",
   "metadata": {},
   "source": [
    "## 2.2 Pytesseract Image to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82fef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_data(file_path, oem=3, psm=3):\n",
    "    bnw = preprocessing(file_path)\n",
    "    custom_config = r\"--oem \"+str(oem)+\" --psm \"+str(psm)\n",
    "    result = pytesseract.image_to_data(bnw, output_type=\"dict\", config=custom_config, lang=\"ind\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8747282",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = image_to_data('Data/2_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3520c804",
   "metadata": {},
   "source": [
    "# 3. Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6ff6ac",
   "metadata": {},
   "source": [
    "## 3.1 Simple Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762c18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_postprocessing(text):\n",
    "    if text[-1] == '\\n':\n",
    "        text = text[:-1]\n",
    "        \n",
    "    text = re.sub('\\n\\n', '\\t', text)\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\t', '\\n', text)\n",
    "    \n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1b914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ocr_text = image_to_string('Data/2_3.png')\n",
    "result = simple_postprocessing(ocr_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff8106",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ocr_text = image_to_string('Data/2_4.png')\n",
    "result = simple_postprocessing(ocr_text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea95ded",
   "metadata": {},
   "source": [
    "## 3.2 Text Localization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfffe31a",
   "metadata": {},
   "source": [
    "Find text coordinate and create bounding box in original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f2d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_localization(tesseract_results, image_path, confidence_threshold = 50):\n",
    "    images = cv2.imread(image_path)\n",
    "    for i in range(0, len(tesseract_results[\"text\"])):\n",
    "\n",
    "        x = tesseract_results[\"left\"][i]\n",
    "        y = tesseract_results[\"top\"][i]\n",
    "        w = tesseract_results[\"width\"][i]\n",
    "        h = tesseract_results[\"height\"][i]\n",
    "\n",
    "        text = tesseract_results[\"text\"][i]\n",
    "        conf = float(tesseract_results[\"conf\"][i])\n",
    "        \n",
    "        # filter out weak confidence text localizations\n",
    "        if conf > confidence_threshold:          \n",
    "            text = \"\".join(text).strip()\n",
    "            cv2.rectangle(images,\n",
    "                          (x, y),\n",
    "                          (x + w, y + h),\n",
    "                          (0, 255, 0), 2)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(images, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c1c345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = image_to_data('Data/2_4.png')\n",
    "bounding_images = text_localization(results, 'Data/2_4.png', confidence_threshold=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72054ddb",
   "metadata": {},
   "source": [
    "# Noisy Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7425d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = image_to_string(\"Data/noise_01.jpg\")\n",
    "result = simple_postprocessing(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b757ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = image_to_string(\"Data/noise_02.jpg\")\n",
    "result = simple_postprocessing(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b4776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = image_to_string(\"Data/1_1.png\")\n",
    "result = simple_postprocessing(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4601ef",
   "metadata": {},
   "source": [
    "# Handle Simple Table Format\n",
    "\n",
    "OCR for simple table and save as csv/excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cfb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = image_to_data('Data/table.png')\n",
    "bounding_images = text_localization(results, 'Data/table.png', confidence_threshold=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6390212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = image_to_string('Data/table.png')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a2b85",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52ee264",
   "metadata": {},
   "source": [
    "#### Image to data have coordinate for each words, use block_num and line_num to get each entry for each tabel and column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79030341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_table(results, threshold_gap = 400, confidence_threshold=70):\n",
    "    result_list = []\n",
    "    uni_par = np.unique(results['block_num'])\n",
    "    for i, pn in enumerate(uni_par):\n",
    "\n",
    "        par_index = np.where(np.array(results['block_num']) == pn)[0]\n",
    "        par_text = np.array(results['text'])[par_index]\n",
    "        par_left = np.array(results['left'])[par_index]\n",
    "        par_width = np.array(results['width'])[par_index]\n",
    "        par_conf = np.array(results['conf'])[par_index]\n",
    "        par_line = np.array(results['line_num'])[par_index]\n",
    "\n",
    "        uni_line = np.unique(par_line)\n",
    "        for j, ln in enumerate(uni_line):\n",
    "            temp_result = []\n",
    "\n",
    "            line_index = np.where(par_line == ln)[0]\n",
    "            line_text = par_text[line_index]\n",
    "            line_left = par_left[line_index]\n",
    "            line_width = par_line[line_index]\n",
    "            line_conf = par_conf[line_index]\n",
    "\n",
    "            temp_result.append([])\n",
    "            k = 0\n",
    "            while k < len(line_text)-1:\n",
    "                if line_text[k] != '' and line_text[k+1] != '':\n",
    "\n",
    "                    end_k = line_left[k]+line_width[k]\n",
    "                    \n",
    "                    if float(line_conf[k]) > confidence_threshold:\n",
    "                        temp_result[-1].append(line_text[k])\n",
    "\n",
    "                    if (line_left[k+1] - end_k) > threshold_gap and temp_result[-1] != []:\n",
    "                        temp_result.append([])\n",
    "\n",
    "                k += 1\n",
    "            temp_result[-1].append(line_text[k])\n",
    "\n",
    "            temp_result = [' '.join(tp) for tp in temp_result]\n",
    "\n",
    "            if temp_result != [''] and temp_result != [' ']:\n",
    "                result_list.append(temp_result)\n",
    "\n",
    "    df = pd.DataFrame(result_list)  \n",
    "    return df\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048fe6c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_path = 'Data/table.png'\n",
    "results = image_to_data(image_path)\n",
    "bounding_images = text_localization(results, image_path, confidence_threshold=70)\n",
    "df = simple_table(results, threshold_gap=400, confidence_threshold=70)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64bee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Data/table2.png'\n",
    "results = image_to_data(image_path)\n",
    "bounding_images = text_localization(results, image_path, confidence_threshold=70)\n",
    "df = simple_table(results, threshold_gap=400, confidence_threshold=70)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e7175",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Data/table6.png'\n",
    "results = image_to_data(image_path)\n",
    "bounding_images = text_localization(results, image_path, confidence_threshold=70)\n",
    "df = simple_table(results, threshold_gap=400, confidence_threshold=70)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e519015",
   "metadata": {},
   "source": [
    "#### simple_table function fail to parse table6.png, try another method\n",
    "#### use coordinate from tesseract result instead of block and line number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_table2(results, threshold_gap = 20, confidence_threshold=70):\n",
    "    text_list = []\n",
    "    top_list = []\n",
    "    left_list = []\n",
    "    width_list = []\n",
    "    conf_list = []\n",
    "\n",
    "    for i, text in enumerate(results['text']):\n",
    "        if text != '' and text != ' ':\n",
    "            top = results['top'][i]\n",
    "            if top_list == []:\n",
    "                top_list.append(top)\n",
    "                text_list.append([])\n",
    "                left_list.append([])\n",
    "                width_list.append([])\n",
    "                conf_list.append([])\n",
    "\n",
    "            min_dist = [1 if np.absolute(tl-top) < 10 else 0 for tl in top_list]\n",
    "            unique = np.unique(min_dist)\n",
    "            if len(unique) == 1 and unique == 0:\n",
    "                top_list.append(top)\n",
    "                text_list.append([])\n",
    "                left_list.append([])\n",
    "                width_list.append([])\n",
    "                conf_list.append([])\n",
    "                top_index = len(top_list)-1\n",
    "            else:\n",
    "                top_index = min_dist.index(1)\n",
    "\n",
    "\n",
    "            text_list[top_index].append(text)\n",
    "            left_list[top_index].append(results['left'][i])\n",
    "            width_list[top_index].append(results['width'][i])\n",
    "            conf_list[top_index].append(results['conf'][i])\n",
    "\n",
    "\n",
    "    result_list = []\n",
    "    for i, line_text in enumerate(text_list):\n",
    "\n",
    "        line_width = width_list[i]\n",
    "        line_left = left_list[i]\n",
    "        line_conf = conf_list[i]\n",
    "        temp_result = [[]]\n",
    "        k = 0\n",
    "        while k < len(line_text)-1:\n",
    "            if line_text[k] != '' and line_text[k+1] != '':\n",
    "\n",
    "                end_k = line_left[k]+line_width[k]\n",
    "\n",
    "                if float(line_conf[k]) > confidence_threshold:\n",
    "                    temp_result[-1].append(line_text[k])\n",
    "\n",
    "                if (line_left[k+1] - end_k) > threshold_gap and temp_result[-1] != []:\n",
    "                    temp_result.append([])\n",
    "\n",
    "            k += 1\n",
    "        temp_result[-1].append(line_text[k])\n",
    "\n",
    "        temp_result = [' '.join(tp) for tp in temp_result]\n",
    "\n",
    "        if temp_result != [''] and temp_result != [' ']:\n",
    "            result_list.append(temp_result)\n",
    "\n",
    "    df = pd.DataFrame(result_list)  \n",
    "    return df\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2503dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Data/table6.png'\n",
    "results = image_to_data(image_path)\n",
    "bounding_images = text_localization(results, image_path, confidence_threshold=70)\n",
    "df = simple_table2(results, threshold_gap=20, confidence_threshold=70)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03da7418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results/table.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4a9b11",
   "metadata": {},
   "source": [
    "# Extract text in any box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c331a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Data/boxes.png\")\n",
    "plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167e8b3",
   "metadata": {},
   "source": [
    "## Box detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' source https://pyimagesearch.com/2015/04/20/sorting-contours-using-python-and-opencv/'''\n",
    "\n",
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    \n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "        key=lambda b:b[1][i], reverse=reverse))\n",
    "\n",
    "    return (cnts, boundingBoxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2e1ce3",
   "metadata": {},
   "source": [
    "\n",
    "#### Simple box detection using opencv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76406576",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Data/boxes2.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray,128,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]\n",
    "\n",
    "H, W, C = image.shape\n",
    "cropped_dir_path = 'crop_image/'\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "idx = 0\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if (w > 50 and h > 50) and w >= 2.5*h:\n",
    "        if h < 0.9*H:\n",
    "            idx += 1\n",
    "            new_img = image[y:y+h, x:x+w]\n",
    "            cv2.imwrite(cropped_dir_path+str(idx) + '.png', new_img)\n",
    "        \n",
    "    if (w > 50 and h > 50) and w < 2.5*h and w >= h:\n",
    "        if w < 0.9*W and h < 0.9*H:\n",
    "            idx += 1\n",
    "            new_img = image[y:y+h, x:x+w]\n",
    "            cv2.imwrite(cropped_dir_path+str(idx) + '.png', new_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315fc50",
   "metadata": {},
   "source": [
    "#### For more advance box detection, try using cv2.getStructuringElement, cv2.HoughLinesP, etc.\n",
    "\n",
    "for example: https://levelup.gitconnected.com/text-extraction-from-a-table-image-using-pytesseract-and-opencv-3342870691ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0cdcd2",
   "metadata": {},
   "source": [
    "## Detect Text in Each Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3eb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"Data/boxes2.png\")\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "thresh = cv2.threshold(gray,128,255,cv2.THRESH_BINARY|cv2.THRESH_OTSU)[1]\n",
    "\n",
    "H, W, C = image.shape\n",
    "custom_config = r\"--oem 3 --psm 3\"\n",
    "\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "(contours, boundingBoxes) = sort_contours(contours, method=\"top-to-bottom\")\n",
    "\n",
    "idx = 0\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if (w > 50 and h > 50) and w >= 2.5*h:\n",
    "        if h < 0.9*H:\n",
    "            idx += 1\n",
    "            new_thresh = thresh[y:y+h, x:x+w]\n",
    "            text = pytesseract.image_to_string(new_thresh, config=custom_config, lang=\"ind\")\n",
    "            print(simple_postprocessing(text))\n",
    "        \n",
    "    if (w > 50 and h > 50) and w < 2.5*h and w >= h:\n",
    "        if w < 0.9*W and h < 0.9*H:\n",
    "            idx += 1\n",
    "            new_thresh = thresh[y:y+h, x:x+w]\n",
    "            text = pytesseract.image_to_string(new_thresh, config=custom_config, lang=\"ind\")\n",
    "            print(simple_postprocessing(text))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f2a7603",
   "metadata": {},
   "source": [
    "# Handle PDF Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2af2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "\n",
    "doc = convert_from_path('Data/table.pdf')\n",
    "\n",
    "for page_number, page_data in enumerate(doc):\n",
    "    image = np.array(page_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5033fdca",
   "metadata": {},
   "source": [
    "# Handwriting Recognition\n",
    "\n",
    "data: https://www.kaggle.com/datasets/landlord/handwriting-recognition\n",
    "\n",
    "some code for handwriting recognition : https://www.kaggle.com/datasets/landlord/handwriting-recognition/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5330629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (primary_tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 | packaged by conda-forge | (default, Sep 29 2021, 19:24:02) \n[Clang 11.1.0 ]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
